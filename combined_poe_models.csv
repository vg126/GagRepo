model_handle,provider,point_cost,context_window_tokens,flags,has_multimodal_input,web_search_type,code_capability_profile,reasoning_profile,comments,,,,,,,,,
GPT-OSS-120B-CS,OpenAI,Not Found,Not Found,None,Yes (Image),Integrated,Specialized,Optimized,Worldâs fastest inference for GPT OSS 120B with Cerebras.,,,,,,,,,
OpenAI-GPT-OSS-120B,OpenAI,Not Found,Not Found,--reasoning_effort,No,Integrated,Specialized,Tunable,Trained on Harmony response format; fits on a single H100 GPU.,,,,,,,,,
OpenAI-GPT-OSS-20B,OpenAI,Not Found,Not Found,--reasoning_effort,No,Integrated,Specialized,Tunable,Compact model for low-latency and edge deployments.,,,,,,,,,
Qwen-3-235B-2507-T,Alibaba,Not Found,262000,None,No,None,High,Optimized,Best instruct model (non-reasoning) among many sources.,,,,,,,,,
Qwen3-235B-2507-FW,Alibaba,Not accessible,256000,None,No,None,High,Standard,Operates in non-thinking mode. Data sent to Fireworks AI.,,,,,,,,,
Qwen3-235B-2507-CS,Alibaba,Not Found,Not Found,None,No,None,High,Standard,World's fastest inference with Cerebras.,,,,,,,,,
Qwen3-Coder-480B-T,Alibaba,Not Found,262144,None,No,None,Specialized,Optimized,480B total parameters MoE model for code generation.,,,,,,,,,
Qwen3-Coder-480B-FW,Alibaba,Not Found,256000,None,No,None,Specialized,Optimized,Scales to 1M tokens with extrapolation. Data sent to Fireworks AI.,,,,,,,,,
Qwen3-235B-A22B-DI,Alibaba,Not accessible,32000,None,No,None,High,Optimized,Quantization: FP8.,,,,,,,,,
Qwen3-235B-A22B,Alibaba,0 points,Not Found,None,No,None,High,Optimized,Fastest implementation of the new Qwen3 235B flagship model.,,,,,,,,,
Qwen3-235B-A22B-N,Alibaba,Not Found,262000,None,No,None,High,Standard,"Does not implement ""thinking mode"". Does not support attachments.",,,,,,,,,
QwQ-32B-T,Alibaba,Not accessible,131000,None,No,None,High,Optimized,"Compact, 32B open-source reasoning model.",,,,,,,,,
MiniMax-M1,MiniMax,100+ points,1000000,None,No,None,Standard,Optimized,Pure text reasoning model; does not process any file types.,,,,,,,,,
o1,OpenAI,4120+ points,200000,--reasoning_effort,Yes (Image),None,High,Tunable,Designed to reason before it responds.,,,,,,,,,
o1-pro,OpenAI,54420+ points,Not Found,--reasoning_effort,Yes (Image),None,High,Tunable,"Tailored for complex, compute- or context-heavy tasks.",,,,,,,,,
o1-mini,OpenAI,385+ points,128000,None,Yes (Image),None,High,Optimized,Small version of OpenAI's o1 model.,,,,,,,,,
ChatGPT-4o-Latest,OpenAI,345+ points,128000,None,No,None,High,Standard,Dynamic model continuously updated. Cannot generate images.,,,,,,,,,
GPT-4o-mini,OpenAI,7+ points,Not Found,None,No,None,Standard,Standard,"Significantly smarter, cheaper, and as fast as GPT-3.5 Turbo.",,,,,,,,,
o3-mini-high,OpenAI,508+ points,200000,--reasoning_effort,Yes (Image),None,High,Tunable,reasoning_effort is set to high by default.,,,,,,,,,
o3-mini,OpenAI,244+ points,200000,--reasoning_effort,Yes (Image),None,High,Tunable,Uses medium reasoning effort by default.GPT-OSS-120B-CS,OpenAI,Not Found,Not Found,None,Yes (Image),Integrated,Specialized,Optimized,Worldâs fastest inference for GPT OSS 120B with Cerebras.
OpenAI-GPT-OSS-120B,OpenAI,Not Found,Not Found,--reasoning_effort,No,Integrated,Specialized,Tunable,Trained on Harmony response format; fits on a single H100 GPU.,,,,,,,,,
OpenAI-GPT-OSS-20B,OpenAI,Not Found,Not Found,--reasoning_effort,No,Integrated,Specialized,Tunable,Compact model for low-latency and edge deployments.,,,,,,,,,
Qwen-3-235B-2507-T,Alibaba,Not Found,262000,None,No,None,High,Optimized,Best instruct model (non-reasoning) among many sources.,,,,,,,,,
Qwen3-235B-2507-FW,Alibaba,Not accessible,256000,None,No,None,High,Standard,Operates in non-thinking mode. Data sent to Fireworks AI.,,,,,,,,,
Qwen3-235B-2507-CS,Alibaba,Not Found,Not Found,None,No,None,High,Standard,World's fastest inference with Cerebras.,,,,,,,,,
Qwen3-Coder-480B-T,Alibaba,Not Found,262144,None,No,None,Specialized,Optimized,480B total parameters MoE model for code generation.,,,,,,,,,
Qwen3-Coder-480B-FW,Alibaba,Not Found,256000,None,No,None,Specialized,Optimized,Scales to 1M tokens with extrapolation. Data sent to Fireworks AI.,,,,,,,,,
Qwen3-235B-A22B-DI,Alibaba,Not accessible,32000,None,No,None,High,Optimized,Quantization: FP8.,,,,,,,,,
Qwen3-235B-A22B,Alibaba,0 points,Not Found,None,No,None,High,Optimized,Fastest implementation of the new Qwen3 235B flagship model.,,,,,,,,,
Qwen3-235B-A22B-N,Alibaba,Not Found,262000,None,No,None,High,Standard,"Does not implement ""thinking mode"". Does not support attachments.",,,,,,,,,
QwQ-32B-T,Alibaba,Not accessible,131000,None,No,None,High,Optimized,"Compact, 32B open-source reasoning model.",,,,,,,,,
MiniMax-M1,MiniMax,100+ points,1000000,None,No,None,Standard,Optimized,Pure text reasoning model; does not process any file types.,,,,,,,,,
o1,OpenAI,4120+ points,200000,--reasoning_effort,Yes (Image),None,High,Tunable,Designed to reason before it responds.,,,,,,,,,
o1-pro,OpenAI,54420+ points,Not Found,--reasoning_effort,Yes (Image),None,High,Tunable,"Tailored for complex, compute- or context-heavy tasks.",,,,,,,,,
o1-mini,OpenAI,385+ points,128000,None,Yes (Image),None,High,Optimized,Small version of OpenAI's o1 model.,,,,,,,,,
ChatGPT-4o-Latest,OpenAI,345+ points,128000,None,No,None,High,Standard,Dynamic model continuously updated. Cannot generate images.,,,,,,,,,
GPT-4o-mini,OpenAI,7+ points,Not Found,None,No,None,Standard,Standard,"Significantly smarter, cheaper, and as fast as GPT-3.5 Turbo.",,,,,,,,,
o3-mini-high,OpenAI,508+ points,200000,--reasoning_effort,Yes (Image),None,High,Tunable,reasoning_effort is set to high by default.,,,,,,,,,
o3-mini,OpenAI,244+ points,200000,--reasoning_effort,Yes (Image),None,High,Tunable,Uses medium reasoning effort by default.Tako,Tako,Not accessible,Not Found,--specificity,No,Dedicated,Standard,Standard,"Transforms questions into interactive, shareable knowledge cards."
Llama-3.1-405B-FP16,Meta,Not accessible,128000,None,No,None,High,Standard,The biggest and best open-source AI model trained by Meta; BF16 precision.,,,,,,,,,
Llama-3.1-8B-FP16,Meta,50 points,128000,None,No,None,Standard,Standard,Smallest and fastest member of the Llama 3.1 family; 128K context length.,,,,,,,,,
Llama-3.1-70B-FP16,Meta,Not accessible,128000,None,No,None,High,Standard,Faster response times compared to the 405B model.,,,,,,,,,
Llama-3-70B-FP16,Meta,Not accessible,128000,None,No,None,High,Standard,A highly efficient and powerful model designed for a variety of tasks.,,,,,,,,,
Qwen-2.5-7B-T,Alibaba,Not accessible,Not Found,None,No,None,High,Standard,"Excels in coding, math, instruction following, and has great multilingual support.",,,,,,,,,
Qwen-2.5-Coder-32B-T,Alibaba,210 points,Not Found,None,No,None,Specialized,Standard,"A powerful model with 32.5B parameters, excelling in coding and math.",,,,,,,,,
QwQ-32B-Preview-T,Alibaba,320 points,Not Found,None,No,None,High,Optimized,Experimental research model focused on advancing AI reasoning capabilities.,,,,,,,,,
Qwen-2.5-72B-T,Alibaba,Not accessible,Not Found,None,No,None,High,Standard,Results on par with Llama-3-405B despite using only one-fifth of the parameters.,,,,,,,,,
Llama-3-8b-Groq,Meta,10 points,Not Found,None,No,None,Standard,Standard,Llama 3 8b powered by the Groq LPUâ¢ Inference Engine.,,,,,,,,,
Llama-3-8B-T,Meta,15 points,Not Found,None,No,None,Standard,Standard,The points price is subject to change.,,,,,,,,,
Hermes-3-70B,Nous Research,Not accessible,Not Found,None,No,None,High,Optimized,"Advanced agentic capabilities, much better roleplaying, and reasoning.",,,,,,,,,
GPT-4-Turbo,OpenAI,406+ points,128000,None,Yes (Image),None,High,Standard,Powered by GPT-4 Turbo with Vision.,,,,,,,,,
GPT-3.5-Turbo-Instruct,OpenAI,19+ points,Not Found,None,No,None,Standard,Standard,Powered by gpt-3.5-turbo-instruct.,,,,,,,,,
GPT-3.5-Turbo-Raw,OpenAI,15+ points,Not Found,None,No,None,Standard,Standard,Powered by gpt-3.5-turbo without a system prompt.,,,,,,,,,
Poe-System-Bot,Poe,Not Found,Not Found,None,No,None,Standard,Standard,A system bot that helps manage the chat.,,,,,,,,,
Qwen3-Coder-480B-N,Alibaba,Not Found,256000,None,No,None,Specialized,Optimized,Claude Sonnet-comparable performance on agentic coding. Does not support attachments.FLUX-pro-1.1-ultra,Not Found,2000 points,Not Found,"--aspect, --raw, --strength",Yes (Image),None,Standard,Standard,State-of-the-art image generation.
DeepSeek-R1-Distill,DeepSeek,150 points,128000,None,No,None,High,Optimized,Fine-tuned version of Llama 3.3 70B served from GroqCloud.,,,,,,,,,
Mistral-Small-3.2,Mistral AI,Not Found,Not Found,None,Yes (Image),None,Standard,Standard,"Description is in German; Open-source, runs on modest hardware.",,,,,,,,,
Mistral-Small-3.1,Mistral AI,Not accessible,128000,None,Yes (Image),None,High,Optimized,24B parameter model with advanced multimodal capabilities.,,,,,,,,,
Mistral-NeMo,Mistral AI / NVIDIA,Not Found,Not Found,None,Yes (Image),None,High,Standard,12B parameter open-source model with extensive multilingual support.,,,,,,,,,
Llama-3.3-70B-Vers,Meta,Not Found,Not Found,None,Yes (Image),None,High,Standard,"Supports analyzing images, PDFs, SVGs, XLSX, WEBP, HTML, etc.",,,,,,,,,
Perplexity-Deep-Research,Perplexity,15167 points,128000,None,No,Dedicated,Standard,Optimized,Research-focused model for multi-step retrieval and synthesis.,,,,,,,,,
Claude-Opus-3,Anthropic,Not accessible,200000,None,No,None,High,Optimized,Handles complex analysis and longer tasks with multiple steps.,,,,,,,,,
Gemini-1.5-Flash,Google,Not Found,Not Found,None,"Yes (Image, Video)",None,Standard,Standard,Optimized for speed. One video per message restriction.,,,,,,,,,
Aya-Vision,Cohere,Not Found,Not Found,None,Yes (Image),None,Standard,Standard,"32B open-weights model, excels in 23 languages in vision and text.",,,,,,,,,
Perplexity-R1-1776,Perplexity,Not Found,128000,None,No,None,High,Optimized,DeepSeek-R1 model post-trained to remove CCP censorship. No web search.,,,,,,,,,
DeepClaude,DeepClaude,Not Found,Not Found,None,No,None,High,Optimized,Combines DeepSeek R1's CoT with Claude's creative/code generation.,,,,,,,,,
Gemma-3-27B,Google,Not accessible,128000,None,Yes (Image),None,High,Optimized,"Successor to Gemma 2, understands over 140 languages.",,,,,,,,,
QwQ-32B-B10,Alibaba,Not accessible,131072,None,No,None,High,Optimized,Medium-sized reasoning model from the Qwen series. Blazing-fast speed.,,,,,,,,,
Qwen3-32B-CS,Alibaba,Not Found,Not Found,None,No,None,High,Standard,Worldâs fastest inference for Qwen 3 32B with Cerebras.,,,,,,,,,
Qwen-2.5-VL-32b,Alibaba,Not accessible,Not Found,None,Yes (Image),None,Standard,Optimized,Strengthened math/problem-solving through reinforcement learning.,,,,,,,,,
Qwen2.5-VL-72B-T,Alibaba,Not accessible,32000,None,"Yes (Image, Video)",None,High,Optimized,Excels in visual and video understanding.,,,,,,,,,
Mistral-Small-3,Mistral AI,10+ points,Not Found,None,No,None,Standard,Standard,Apache 2.0 license. Comparable to Llama-3.3-70B.,,,,,,,,,
DeepSeek-V3-DI,DeepSeek,Not accessible,64000,None,No,None,High,Optimized,Quantization: FP8. Data sent to DeepInfra.,,,,,,,,,
Grok-2,xAI,209+ points,Not Found,None,Yes (Image),None,High,Optimized,Does not have access to real-time information from X or the internet.Claude-Sonnet-3.7-Reasoning,Anthropic,2371+ points,200000,--thinking_budget,No,None,High,Tunable,Reasoning on by default. Recommended for complex math or coding.
Inception-Mercury-Coder,Inception Labs,14+ points,Not Found,None,No,None,Specialized,Optimized,First diffusion large language model (dLLM). Runs 5-10x faster than comparable models.,,,,,,,,,
Mistral-Medium,Mistral AI,181+ points,32000,None,No,None,Standard,Standard,Stronger than Mixtral-8x7b and Mistral-7b on benchmarks.,,,,,,,,,
Llama-4-Scout,Meta,30 points,131000,None,Yes (Image),None,High,Standard,"Versatile, general-purpose LLM.",,,,,,,,,
Llama-4-Maverick-T,Meta,Not accessible,500000,None,Yes (Image),None,Standard,Standard,128-expert MoE powerhouse for multilingual image/text understanding.,,,,,,,,,
Llama-3.3-70B-FW,Meta,140 points,Not Found,None,No,None,High,Standard,Hosted by Fireworks AI. Delivers leading performance for text-based use cases.,,,,,,,,,
Llama-3.3-70B,Meta,130 points,Not Found,None,No,None,High,Standard,Similar performance as Llama 3.1 405B while being faster and smaller.,,,,,,,,,
DeepSeek-R1-FW,DeepSeek,600 points,164000,None,No,None,High,Optimized,Explains its chain of thought. Data sent to Fireworks AI.,,,,,,,,,
DeepSeek-R1-DI,DeepSeek,200 points,64000,None,No,None,High,Optimized,Quantization: FP8. Data sent to DeepInfra.,,,,,,,,,
DeepSeek-R1-N,DeepSeek,Not Found,Not Found,None,No,None,High,Optimized,Does not accept attachments.,,,,,,,,,
GPT-Researcher,Tavily,Variable points,Not Found,None,No,Dedicated,Standard,Standard,Powered by Tavily's search engine. Based on open source project.,,,,,,,,,
Gemini-1.5-Pro,Google,32+ points,Not Found,None,"Yes (Image, Video)",None,High,Optimized,"Accepts text, image, and video input. One video per message.",,,,,,,,,
Bagoodex-Web-Search,Bagoodex,Not Found,Not Found,None,Yes (Image),Dedicated,Standard,Standard,"Offers instant access to videos, images, weather, and more.",,,,,,,,,
GPT-4o-Search,OpenAI,1235+ points,128000,None,No,Integrated,High,Standard,Fine-tuned for searching the web. Does not support image search.,,,,,,,,,
GPT-4o-mini-Search,OpenAI,836+ points,128000,None,No,Integrated,Standard,Standard,Less expensive version of GPT-4o-Search. Does not support image search.,,,,,,,,,
Reka-Research,Reka,Not Found,Not Found,None,No,Dedicated,Standard,Optimized,State-of-the-art agentic AI that browses the web.,,,,,,,,,
Perplexity-Sonar,Perplexity,Not accessible,127000,None,No,Dedicated,Standard,Standard,"Delivers real-time, web-connected search results with citations.",,,,,,,,,
Perplexity-Sonar-Pro,Perplexity,1667 points,200000,None,No,Dedicated,Standard,Standard,Enhanced version with double the citations and larger context.,,,,,,,,,
Perplexity-Sonar-Rsn-Pro,Perplexity,2967 points,128000,None,No,Dedicated,Standard,Optimized,Operates on the open-sourced uncensored R1-1776 model.,,,,,,,,,
Perplexity-Sonar-Rsn,Perplexity,1234 points,128000,None,No,Dedicated,Standard,Optimized,Operates on the open-sourced uncensored R1-1776 model.Llama-4-Maverick-B10,Meta,Not accessible,1000000,--page_range,Yes (Image),None,High,Standard,Ultra-fast implementation by Baseten. Supports images and PDFs.
Llama-3.1-70B,Meta,18+ points,Not Found,None,No,None,High,Standard,Context window shortened to optimize for speed and cost.,,,,,,,,,
Llama-3.1-405B,Meta,65+ points,Not Found,None,No,None,High,Standard,Pinnacle of Meta's Llama 3.1 family. Optimized for chat use cases.,,,,,,,,,
Llama-3.1-405B-T,Meta,335 points,128000,None,No,None,High,Standard,Points price is subject to change.,,,,,,,,,
Llama-3.3-70B-DI,Meta,Not accessible,128000,None,No,None,High,Standard,Quantization: FP8. Data sent to DeepInfra.,,,,,,,,,
Llama-3.1-8B-DI,Meta,Not accessible,128000,None,No,None,Standard,Standard,Quantization: FP16. Data sent to DeepInfra.,,,,,,,,,
DeepSeek-R1-Turbo-DI,DeepSeek,Not accessible,32000,None,No,None,High,Optimized,Turbo model is quantized for higher speeds. Quantization: FP4. Data sent to DeepInfra.,,,,,,,,,
DeepSeek-V3-Turbo-DI,DeepSeek,Not accessible,32000,None,No,None,High,Optimized,Turbo variant is quantized for higher speeds. Quantization: FP4. Data sent to DeepInfra.,,,,,,,,,
Phi-4-DI,Microsoft,Not accessible,16000,None,No,None,Standard,Optimized,14B parameter model. Works best with English. Data sent to DeepInfra.,,,,,,,,,
Mistral-7B-v0.3-DI,Mistral AI,Not accessible,32000,None,No,None,Standard,Standard,Quantization: FP16. Data sent to DeepInfra.,,,,,,,,,
Aya-Expanse-32B,Cohere,Not accessible,Not Found,None,No,None,Standard,Standard,32B open-weight research release with advanced multilingual capabilities in 23 languages.,,,,,,,,,
Llama-3.1-Nemotron,NVIDIA,200 points,Not Found,None,No,None,High,Optimized,"Excels in understanding, following instructions, writing and performing coding tasks.",,,,,,,,,
LivePortrait,fal.ai,Not Found,Not Found,None,"Yes (Image, Video)",None,Standard,Standard,Animates given portraits with the motion's in the video.,,,,,,,,,
Llama-3.1-405B-FW,Meta,Not accessible,128000,None,No,None,High,Standard,Instruction tuned text only models.,,,,,,,,,
Llama-3.1-8B-T-128k,Meta,100 points,128000,None,No,None,Standard,Standard,Points price is subject to change.,,,,,,,,,
Llama-3.1-70B-FW,Meta,Not accessible,128000,None,No,None,High,Standard,Optimized for multilingual dialogue use cases.,,,,,,,,,
Llama-3.1-70B-T,Meta,Not accessible,128000,None,No,None,High,Standard,Points price is subject to change.,,,,,,,,,
Llama-3.1-8B-FW,Meta,Not accessible,128000,None,No,None,Standard,Standard,Optimized for multilingual dialogue use cases.,,,,,,,,,
Llama-3.1-8B,Meta,20 points,Not Found,None,No,None,Standard,Standard,Context window has been shortened to optimize for speed and cost.,,,,,,,,,
Claude-Haiku-3,Anthropic,20+ points,Not Found,None,No,None,Standard,Standard,"Outperforms models in its intelligence category on performance, speed and cost.Assistant",Poe,Variable points,Variable,None,Yes (Image),Integrated,Standard,Standard,Routes queries to other models based on task.
GPT-5-Chat,OpenAI,Not Found,Not Found,None,Yes (Image),None,High,Standard,Snapshot used in ChatGPT; 90% chat history cache discount.,,,,,,,,,
GPT-5,OpenAI,Not Found,400000,--reasoning_effort,Yes (Image),None,High,Tunable,90% chat history cache discount.,,,,,,,,,
Claude-Sonnet-4,Anthropic,938+ points,200000,--thinking_budget,No,None,Standard,Tunable,Customizable thinking budget up to 30k tokens.,,,,,,,,,
Claude-Opus-4.1,Anthropic,Not Found,200000,--thinking_budget,No,None,High,Tunable,Customizable thinking budget up to 32k tokens.,,,,,,,,,
Gemini-2.5-Pro,Google,335+ points,1000000,--thinking_budget,Yes (Image),Integrated,High,Tunable,Supports web search.,,,,,,,,,
Grok-4,xAI,Not Found,Not Found,None,Yes (Image),None,High,Optimized,State-of-the-art in coding and reasoning.,,,,,,,,,
GPT-5-mini,OpenAI,Not Found,400000,--reasoning_effort,Yes (Image),None,Standard,Tunable,Matches or beats GPT-4.1 in many tasks. 90% chat history cache discount.,,,,,,,,,
GPT-4o,OpenAI,Variable points,128000,None,Yes (Image),None,High,Standard,Uses GPT-Image-1 for image generation.,,,,,,,,,
GPT-5-nano,OpenAI,Not Found,400000,--reasoning_effort,Yes (Image),None,Standard,Tunable,Extremely fast model for summarization/categorization. 90% chat history cache discount.,,,,,,,,,
o3-pro,OpenAI,4242+ points,Not Found,--reasoning_effort,Yes (Image),None,High,Tunable,"Especially capable at math, science, and coding.",,,,,,,,,
GPT-OSS-120B-T,OpenAI,Not Found,Not Found,None,No,None,Specialized,Optimized,Apache 2.0 license. Fully open model.,,,,,,,,,
GPT-OSS-20B-T,OpenAI,Not Found,Not Found,None,No,None,Specialized,Optimized,Apache 2.0 license. Designed for single-GPU deployment.,,,,,,,,,
Gemini-2.5-Flash,Google,9+ points,1000000,--thinking_budget,Yes (Image),Integrated,Standard,Tunable,Upgrade in reasoning and search from 2.0 Flash.,,,,,,,,,
Gemini-2.5-Flash-Lite-Preview,Google,Not Found,1000000,--thinking_budget,Yes (Image),Integrated,Standard,Tunable,Lightweight and cost-efficient version.,,,,,,,,,
DeepSeek-R1,DeepSeek,600 points,164000,None,No,None,High,Optimized,Top open-source reasoning LLM. Data sent to Together AI.,,,,,,,,,
DeepSeek-V3,DeepSeek,415 points,131000,None,No,None,High,Optimized,Top open-source LLM. Data sent to Together AI.,,,,,,,,,
Kimi-K2,Moonshot AI,Not Found,Not Found,None,No,None,High,Optimized,Mixture-of-experts (MoE) model optimized for agentic capabilities.,,,,,,,,,
Kimi-K2-T,Moonshot AI,Not Found,Not Found,None,No,None,High,Optimized,Mixture-of-experts (MoE) model.,,,,,,,,,
Kimi-K2-Instruct-N,Moonshot AI,Not Found,Not Found,None,No,None,High,Optimized,MoE model designed for tool use and autonomous problem-solving.,,,,,,,,,
o4-mini,OpenAI,255+ points,200000,--reasoning_effort,Yes (Image),None,High,Tunable,"High intelligence for science, math, and coding.",,,,,,,,,
GPT-4.1,OpenAI,196+ points,1000000,None,Yes (Image),None,High,Standard,75% chat history cache discount.,,,,,,,,,
o3,OpenAI,425+ points,200000,--reasoning_effort,Yes (Image),None,High,Tunable,State-of-the-art intelligence.,,,,,,,,,
Llama-4-Scout-B10,Meta,100 points,8000000,--page_range,Yes (Image),None,High,Standard,Largest context window on Poe. Supports images and PDFs.,,,,,,,,,
Llama-4-Maverick,Meta,50 points,1050000,None,Yes (Image),None,Standard,Standard,SOTA intelligence and fast performance.,,,,,,,,,
Grok-3,xAI,907+ points,131000,None,Yes (Image),None,High,Optimized,Uses Grok 2 for native vision. No access to X data feed on Poe.,,,,,,,,,
Grok-3-Mini,xAI,39+ points,131000,--reasoning_effort,Yes (Image),None,Standard,Tunable,No access to X data feed on Poe.,,,,,,,,,
o3-deep-research,OpenAI,95410+ points,Not Found,None,No,Dedicated,Standard,Standard,Powered by o3 model. For complex research questions.,,,,,,,,,
o4-mini-deep-research,OpenAI,109+ points,Not Found,None,No,Dedicated,Standard,Standard,Powered by o4-mini model. For complex research questions.,,,,,,,,,
Claude-Opus-4,Anthropic,4951+ points,200000,--thinking_budget,No,None,High,Tunable,Customizable thinking budget up to 30k tokens.,,,,,,,,,
Claude-Opus-4-Reasoning,Anthropic,Not available,200000,--thinking_budget,No,None,High,Tunable,Customizable thinking budget up to 30k tokens.,,,,,,,,,
Claude-Sonnet-4-Reasoning,Anthropic,1628+ points,200000,--thinking_budget,No,None,Standard,Tunable,Customizable thinking budget up to 60k tokens.,,,,,,,,,
Web-Search,Google,Variable points,Not Found,None,No,Dedicated,Standard,Standard,Powered by Gemini 2.0 Flash.Deepseek-V3-FW,DeepSeek,300 points,131000,None,No,None,High,Optimized,"Data sent to Fireworks, a US-based company."
GPT-4.1-mini,OpenAI,28+ points,1000000,None,Yes (Image),None,Standard,Standard,"Small, fast & affordable model that matches or beats GPT-4o.",,,,,,,,,
GPT-4.1-nano,OpenAI,8+ points,1000000,None,Yes (Image),None,Standard,Standard,Extremely fast and cheap model for summarization/categorization.,,,,,,,,,
Llama-4-Scout-T,Meta,35 points,300000,None,Yes (Image),None,High,Standard,"16-expert MoE model, excels at multi-document analysis.",,,,,,,,,
Llama-3-70b-Groq,Meta,75 points,Not Found,None,No,None,High,Standard,Powered by the Groq LPUâ¢ Inference Engine.,,,,,,,,,
Llama-4-Scout-CS,Meta,Not Found,Not Found,None,Yes (Image),None,High,Standard,Worldâs fastest inference for Llama 4 Scout with Cerebras.,,,,,,,,,
Claude-Sonnet-3.7,Anthropic,1044+ points,200000,--thinking_budget,No,None,Standard,Tunable,"Hybrid reasoning model. Thinking budget up to 16,384 tokens.",,,,,,,,,
Claude-Sonnet-3.5,Anthropic,297+ points,200000,None,Yes (Image),None,High,Optimized,"October 22, 2024 model snapshot. Excels in visual processing.",,,,,,,,,
Claude-Haiku-3.5,Anthropic,Not available,Not Found,None,No,None,Standard,Standard,Latest generation of Anthropic's fastest model.,,,,,,,,,
Claude-Opus-4-Search,Anthropic,1134+ points,200000,--thinking_budget,No,Integrated,High,Tunable,Access to real-time information. Thinking budget up to 126k tokens.,,,,,,,,,
Claude-Sonnet-4-Search,Anthropic,227+ points,200000,--thinking_budget,No,Integrated,Standard,Tunable,Access to real-time information. Thinking budget up to 126k tokens.,,,,,,,,,
Gemini-2.0-Flash-Lite,Google,5+ points,1000000,None,No,None,Standard,Standard,Spiritual successor to Gemini 1.5 Flash. Does not support web search.,,,,,,,,,
Claude-Sonnet-3.7-Search,Anthropic,Not available,200000,--thinking_budget,No,Integrated,Standard,Tunable,Access to real-time information. Thinking budget up to 126k tokens.,,,,,,,,,
Claude-Sonnet-3.5-Search,Anthropic,Not available,Not Found,None,Yes (Image),Integrated,High,Optimized,Access to real-time information.,,,,,,,,,
Claude-Haiku-3.5-Search,Anthropic,Not available,Not Found,None,No,Integrated,Standard,Standard,Access to real-time information.,,,,,,,,,
Gemini-2.0-Flash,Google,7+ points,1000000,None,Yes (Image),Integrated,High,Optimized,Outperforms 1.5 Pro on key benchmarks at twice the speed.,,,,,,,,,
Gemini-2.0-Flash-Preview,Google,2 points,Not Found,None,Yes (Image),None,Standard,Standard,"Built-in image generation, understands visuals and text. No web search.",,,,,,,,,
GLM-4.5,Zhipu AI,Not Found,Not Found,None,Yes (Image),None,High,Optimized,"355B total parameters. Unifies reasoning, coding, and agent capabilities.",,,,,,,,,
GPT-OSS-120B,OpenAI,Not Found,Not Found,None,No,Integrated,Specialized,Optimized,Apache 2.0 license. Text-only. Does not support attachments.,,,,,,,,,
GPT-OSS-20B,OpenAI,Not Found,Not Found,None,No,Integrated,Specialized,Optimized,Apache 2.0 license. Designed for edge devices. Does not accept attachments.Gemini-1.5-Pro-Search,Google,47+ points,Not Found,None,No,Integrated,High,Optimized,Grounding model currently supports text only.
Gemini-1.5-Flash-Search,Google,4+ points,Not Found,None,No,Integrated,Standard,Standard,Grounding model currently supports text only.,,,,,,,,,
Mixtral8x22b-Inst-FW,Mistral AI,120 points,Not Found,None,No,None,High,Standard,Mixture-of-Experts instruct model from Mistral hosted by Fireworks.,,,,,,,,,
Command-R,Cohere,170 points,Not Found,None,No,Integrated,Standard,Standard,Can search the web and respond in over 10 languages.,,,,,,,,,
Mistral-Large-2,Mistral AI,231+ points,128000,None,No,None,High,Optimized,Top-tier reasoning capabilities for complex multilingual tasks.,,,,,,,,,
Reka-Core,Reka,1250 points,8000,None,"Yes (Image, Video)",None,Standard,Standard,Reka's largest and most capable multimodal model.,,,,,,,,,
Reka-Flash,Reka,40 points,Not Found,None,"Yes (Image, Video)",None,Standard,Standard,Efficient 21B multimodal model optimized for fast workloads.,,,,,,,,,
Command-R-Plus,Cohere,1130 points,Not Found,None,No,Integrated,High,Standard,Supercharged version of Command R.,,,,,,,,,
Claude-Sonnet-3.5-June,Anthropic,Not accessible,Not Found,None,Yes (Image),None,High,Optimized,Legacy June 2024 snapshot; generally more verbose.,,,,,,,,,
GPT-3.5-Turbo,OpenAI,14+ points,16384,None,No,None,Standard,Standard,Powerful language generation system.,,,,,,,,,
Qwen2.5-Coder-32B,Alibaba,50 points,Not Found,None,No,None,Specialized,Standard,Latest series of code-specific Qwen large language models.,,,,,,,,,
Qwen2-72B-Instruct-T,Alibaba,190 points,Not Found,None,No,None,High,Standard,Excels particularly in Chinese-language queries.,,,,,,,,,
Qwen-72B-T,Alibaba,125 points,Not Found,None,No,None,High,Standard,Excels particularly in Chinese-language queries. (Qwen1.5),,,,,,,,,
Gemma-2-27b-T,Google,90 points,Not Found,None,No,None,High,Standard,"For most use cases, Gemini models will produce better results.",,,,,,,,,
Llama-3-70B-T,Meta,75 points,Not Found,None,No,None,High,Standard,"For most use cases, Llama-3.3-70B will perform better.",,,,,,,,,
GPT-4o-Aug,OpenAI,300 points,Not Found,None,Yes (Image),None,High,Standard,August 2024 model snapshot of GPT-4o.,,,,,,,,,
GPT-4-Classic,OpenAI,757+ points,Not Found,None,Yes (Image),None,High,Standard,Powered by gpt-4-0613 for text and gpt-4o for images.,,,,,,,,,
GPT-4-Classic-0314,OpenAI,Not accessible,Not Found,None,Yes (Image),None,High,Standard,Powered by gpt-4-0314 for text and gpt-4o for images.,,,,,,,,,
Solar-Pro-2,Upstage,Not Found,64000,None,No,Integrated,High,Optimized,31B parameter model with world-class multilingual support.,,,,,,,,,
Mistral-7B-v0.3-T,Mistral AI,45 points,Not Found,None,No,None,Standard,Standard,Points price is subject to change.,,,,,,,,,
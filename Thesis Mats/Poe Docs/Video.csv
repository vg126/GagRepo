model_handle,provider,point_cost,generation_mode,max_duration_seconds,max_resolution,flags,comments
Veo-3,,,Text/Image-to-Video,8,,,"Veo 3 creates incredibly high-quality videos in a wide range of subjects and styles. It brings an improved understanding of real-world physics and the nuances of human movement and expression, which helps improve its detail and realism overall. Veo 3 understands the unique language of cinematography: ask it for a genre, specify a lens, suggest cinematic effects and Veo 3 will deliver in 8-second clips. Supports text-to-video as well as image-to-video. Note: currently has low rate limit so you may need to retry your request at times of peak usage. Veo 3 creates incredibly high-quality videos in a wide range of subjects and styles. It brings an improved understanding of real-world physics and the nuances of human movement and expression, which helps improve its detail and realism overall. Veo 3 understands the unique language of cinematography: ask it for a genre, specify a lens, suggest cinematic effects and Veo 3 will deliver in 8-second clips. Supports text-to-video as well as image-to-video. Note: currently has low rate limit so you may need to retry your request at times of peak usage."
Veo-3-Fast,,,Text-to-Video,,,--aspect --generate_audio --negative_prompt,"Veo-3 Fast is a faster and more cost effective version of Google's Veo 3. Use `--aspect` to set the aspect ratio of the generated image (one of `16:9`, `1:1`, `9:16`. Use `--generate_audio` to generate audio with your video at a higher cost. Use to set negative prompt option `blur`, `low resolution`, `poor resolution`. This is a text to video generation model only."
Runway-Gen-4-Turbo,,,Text/Image-to-Video,10,,--aspect_ratio --duration,"Runway's Gen-4 Turbo model creates best-in-class, controllable, and high-fidelity video generations based on your prompts. Both text inputs (max 1000 characters) and image inputs are supported, but we recommend using image inputs for best results. Use (16:9, 1:1, 9:16, landscape, portrait) for landscape/portrait videos. Use (5, 10) to specify video length in seconds. Full prompting guide here: https://help.runwayml.com/hc/en-us/articles/39789879462419-Gen-4-Video-Prompting-Guide"
Hailuo-Director-01,,,Text/Image-to-Video,,,,"Generate video clips more accurately with respect to natural language descriptions and using camera movement instructions for shot control. Both text-to-video and image-to-video are supported. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645 Generate video clips more accurately with respect to natural language descriptions and using camera movement instructions for shot control. Both text-to-video and image-to-video are supported. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645"
Hailuo-02,,,Text/Image-to-Video,6,768p,,"Hailuo-02, MiniMax's latest video generation model. Generates 6-second, 768p videos, just submit a text prompt or an image with a prompt describing the desired video behavior, and it will create it; typically takes ~5 minutes for generation time. Strong motion effects and ultra-clear quality. Hailuo-02, MiniMax's latest video generation model. Generates 6-second, 768p videos, just submit a text prompt or an image with a prompt describing the desired video behavior, and it will create it; typically takes ~5 minutes for generation time. Strong motion effects and ultra-clear quality."
Wan-2.2,,,Text-to-Video,5,720p,--aspect,"Wan-2.2 is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. Use `--aspect` to set the aspect ratio (One of `16:9`, `1:1`, `9:16`) for text-to-video requests. Duration is limited to 5 seconds only with up to 720p resolution. Wan-2.2 is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. Use `--aspect` to set the aspect ratio (One of `16:9`, `1:1`, `9:16`) for text-to-video requests. Duration is limited to 5 seconds only with up to 720p resolution."
Sora,,,Text-to-Video,,1080p,--duration --resolution --aspect,"Sora is OpenAI's video generation model. Use `--duration` to set the duration of the generated video, and `--resolution` to set the video's resolution (480p, 720p, or 1080p). Set the aspect ratio of the generated video with `--aspect` (Valid aspect ratios are 16:9, 1:1, 9:16). This is a text-to-video model only."
Seedance-1.0-Pro,,,Text/Image-to-Video,10,1080p,--aspect --resolution --duration,"Seedance is a video generation model with text-to-video and image-to-video capabilities. It achieves breakthroughs in semantic understanding and prompt following. Use `--aspect` to set the aspect ratio (available values: `21:9`, `16:9`, `4:3`, `1:1`, `3:4`, `9:16`). Use `--resolution` (one of `480p` and `1080p` to set the video resolution. `--duration` (5 or 10) sets the video duration. Number of video tokens calculated for pricing is approximately: `height * width * fps * duration / 1024)."
Seedance-1.0-Lite,,,Text/Image-to-Video,10,720p,--aspect --resolution --duration,"Seedance is a video generation model with text-to-video and image-to-video capabilities. It achieves breakthroughs in semantic understanding and prompt following. Use `--aspect` to set the aspect ratio (available values: `16:9`, `4:3`, `1:1` and `9:21`). Use `--resolution` (one of `480p` and `720p` to set the video resolution. `--duration` (5 or 10) sets the video duration. Number of video tokens calculated for pricing is approximately: `height * width * fps * duration / 1024)."
Kling-2.1-Master,,,Image-to-Video,10,,--negative_prompt --cfg_scale --aspect --duration,"Kling 2.1 Master: The premium endpoint for Kling 2.1, designed for top-tier image-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision. Use `--negative_prompt` to send a negative prompt, and `--cfg_scale` to send a classifier-free guidance scale between 0.0 and 1.0 (inclusive). Use `--aspect` to set the aspect ratio (One of `16:9`, `9:16` and `1:1`). Use to set either 5 second or 10 second video."
Kling-2.1-Pro,,,Image-to-Video,10,,--negative_prompt --aspect --duration --cfg_scale ," Kling 2.1 Pro is an advanced endpoint for the Kling 2.1 model, offering professional-grade videos with enhanced visual fidelity, precise camera movements, and dynamic motion control, perfect for cinematic storytelling. Use `--negative_prompt` to send a negative prompt, and `--cfg_scale` to send a classifier-free guidance scale between 0.0 and 1.0 (inclusive). Use `--aspect` to set the aspect ratio (One of `16:9`, `9:16` and `1:1`). Set video duration to one of `5` or `10` seconds with `--duration`."
Kling-2.1-Std,,,Image-to-Video,10,,--negative_prompt --aspect --duration --cfg_scale ,"Kling 2.1 Standard is a cost-efficient endpoint for the Kling 2.1 model, delivering high-quality image-to-video generation. Use `--negative_prompt` to send a negative prompt, and `--cfg_scale` to send a classifier-free guidance scale between 0.0 and 1.0 (inclusive). Use `--aspect` to set the aspect ratio (One of `16:9`, `9:16` and `1:1`). Set video duration to one of `5` or `10` seconds with `--duration`."
Veo-2,,,Text/Image-to-Video,8,,--aspect-ratio,"Veo 2 creates incredibly high-quality videos in a wide range of subjects and styles. It brings an improved understanding of real-world physics and the nuances of human movement and expression, which helps improve its detail and realism overall. Veo 2 understands the unique language of cinematography: ask it for a genre, specify a lens, suggest cinematic effects and Veo 2 will deliver in 8-second clips. Use --aspect-ratio (16:9 or 9:16) to customize video aspect ratio. Supports text-to-video as well as image-to-video. Non english input will be translated first. Note: currently has low rate limit so you may need to retry your request at times of peak usage. Veo 2 creates incredibly high-quality videos in a wide range of subjects and styles. It brings an improved understanding of real-world physics and the nuances of human movement and expression, which helps improve its detail and realism overall. Veo 2 understands the unique language of cinematography: ask it for a genre, specify a lens, suggest cinematic effects and Veo 2 will deliver in 8-second clips. Use (16:9 or 9:16) to customize video aspect ratio. Supports text-to-video as well as image-to-video. Non english input will be translated first. Note: currently has low rate limit so you may need to retry your request at times of peak usage."
Ray2,,,Text/Image-to-Video,9,4k,,"Ray2 is a large–scale video generative model capable of creating realistic visuals with natural, coherent motion. It has strong understanding of text instructions and can also take image input. Can produce videos from 540p to 4k resolution and with either 5/9s durations. Ray2 is a large–scale video generative model capable of creating realistic visuals with natural, coherent motion. It has strong understanding of text instructions and can also take image input. Can produce videos from 540p to 4k resolution and with either 5/9s durations."
Runway,,,Text/Image-to-Video,10,,--aspect_ratio --duration,"--duration Runway's Gen-3 Alpha Turbo model creates best-in-class, controllable, and high-fidelity video generations based on your prompts. Both text inputs (max 1000 characters) and image inputs are supported, but we recommend using image inputs for best results. Use (16:9, 9:16, landscape, portrait) for landscape/portrait videos. Use (5, 10) to specify video length in seconds."
Wan-2.1,,,Text-to-Video,,,,Wan-2.1 is a text-to-video model that generates high-quality videos with high visual quality and motion diversity from text prompts. Wan-2.1 is a text-to-video model that generates high-quality videos with high visual quality and motion diversity from text prompts.
Hailuo-Live,,,Image-to-Video,,,,"Hailuo Live, the latest model from Minimax, sets a new standard for bringing still images to life. From breathtakingly vivid motion to finely tuned expressions, this state-of-the-art model enables your characters to captivate, move, and shine like never before. It excels in bring art and drawings to life, exceptional realism without morphing, emotional range, and unparalleled character consistency. Hailuo Live, the latest model from Minimax, sets a new standard for bringing still images to life. From breathtakingly vivid motion to finely tuned expressions, this state-of-the-art model enables your characters to captivate, move, and shine like never before. It excels in bring art and drawings to life, exceptional realism without morphing, emotional range, and unparalleled character consistency."
Hailuo-AI,,,Text/Image-to-Video,,,,Best-in-class text and image to video model by MiniMax. Best-in-class text and image to video model by MiniMax.
Dream-Machine,,,Text/Image-to-Video,,,--aspect_ratio --loop,"Luma AI's Dream Machine is an AI model that makes high-quality, realistic videos fast from text and images. Iterate at the speed of thought, create action-packed shots, and dream worlds with consistent characters on Poe today! To specify the aspect ratio of your video add (1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21). To loop your video add True."
Kling-2.0-Master,,,Text/Image-to-Video,,,--negative_prompt --aspect --cfg_scale ,"Generate high-quality videos from text or images using Kling 2.0 Master. Use `--negative_prompt` to send a negative prompt, and `--cfg_scale` to send a classifier-free guidance scale between 0.0 and 1.0 (inclusive). Use `--aspect` to set the aspect ratio (One of `16:9`, `9:16` and `1:1`)."
Kling-1.6-Pro,,,Image-to-Video,10,,--aspect --duration,"Kling v1.6 video generation bot, hosted by fal.ai. For best results, upload an image attachment. Use `--aspect` to set the aspect ratio. Allowed values are `16:9`, `9:16` and `1:1`. Use `--duration` to set the duration of the generated video (5 or 10 seconds)."
Kling-1.5-Pro,,,Image-to-Video,,,--aspect --duration,"Kling v1.5 video generation bot, hosted by fal.ai. For best results, upload an image attachment. Use `--aspect` to set the aspect ratio. Allowed values are `16:9`, `9:16` and `1:1`. Use `--duration` to set the duration of the generated video. Kling v1.5 video generation bot, hosted by fal.ai. For best results, upload an image attachment. Use `--aspect` to set the aspect ratio. Allowed values are `16:9`, `9:16` and `1:1`. Use `--duration` to set the duration of the generated video."
Mochi-preview,,,Text/Image-to-Video,,,,Open state-of-the-art video generation model with high-fidelity motion and strong prompt adherence. Supports both text-to-video and image-to-video. Open state-of-the-art video generation model with high-fidelity motion and strong prompt adherence. Supports both text-to-video and image-to-video.
Pika,,,Text/Image-to-Video,,,--aspect,"Pika's video generation models. Select between Turbo, 2.1, 2.2, or Pikaffect. To adjust the aspect ratio of your image add --aspect (1:1, 5:2, 16:9, 4:3, 4:5, 9:16). Image to video is supported on all models, and multiple images are supported for 2.2 with an IngredientMode selected. Pika's video generation models. Select between Turbo, 2.1, 2.2, or Pikaffect. To adjust the aspect ratio of your image add (1:1, 5:2, 16:9, 4:3, 4:5, 9:16). Image to video is supported on all models, and multiple images are supported for 2.2 with an IngredientMode selected."
Kling-Pro-Effects,,,Image-to-Video,,,--effect,"Generate videos with effects like squishing an object, two people hugging, making heart gestures, etc. using Kling-Pro-Effects. Requires an image input. Send a single image for `squish` and `expansion` effects and two images (of people) for `hug`, `kiss`, and `heart_gesture` effects. Set effect with --effect. Default effect: `squish`. Generate videos with effects like squishing an object, two people hugging, making heart gestures, etc. using Kling-Pro-Effects. Requires an image input. Send a single image for `squish` and `expansion` effects and two images (of people) for `hug`, `kiss`, and `heart_gesture` effects. Set effect with --effect. Default effect: `squish`."
Pixverse-v4.5,,,Text/Image-to-Video,8,1080p,--negative_prompt --duration --resolution --effect --style --seed --aspect,"Pixverse v4.5 is a video generation model capable of generating high quality videos in under a minute. Use `--negative_prompt` to set the negative prompt. Use `--duration` to set the video duration (5 or 8 seconds). Set the resolution (360p,540p,720p or 1080p) using `--resolution`. Send 1 image to perform an image-to-video task or a video effect generation task, and 2 images to perform a video transition task, using the first image as the first frame and the second image as the last frame. Use `--effect` to set the video generation effect, provided 1 image is given (Options: `Kiss_Me_AI`, `Kiss`, `Muscle_Surge`, `Warmth_of_Jesus`, `Anything,_Robot`, `The_Tiger_Touch`, `Hug`, `Holy_Wings`, `Hulk`, `Venom`, `Microwave`). Use `--style` to set the video generation style (for text-to-video,image-to-video, and transition only, options: `anime`, `3d_animation`, `clay`, `comic`, `cyberpunk`). Use `--seed` to set the seed and `--aspect` to set the aspect ratio. --negative_prompt, --duration, --resolution, --effect, --style, --seed, Pixverse v4.5 is a video generation model capable of generating high quality videos in under a minute. Use `--negative_prompt` to set the negative prompt. Use `--duration` to set the video duration (5 or 8 seconds). Set the resolution (360p,540p,720p or 1080p) using `--resolution`. Send 1 image to perform an image-to-video task or a video effect generation task, and 2 images to perform a video transition task, using the first image as the first frame and the second image as the last frame. Use `--effect` to set the video generation effect, provided 1 image is given (Options: `Kiss_Me_AI`, `Kiss`, `Muscle_Surge`, `Warmth_of_Jesus`, `Anything,_Robot`, `The_Tiger_Touch`, `Hug`, `Holy_Wings`, `Hulk`, `Venom`, `Microwave`). Use `--style` to set the video generation style (for text-to-video,image-to-video, and transition only, options: `anime`, `3d_animation`, `clay`, `comic`, `cyberpunk`). Use `--seed` to set the seed and `--aspect` to set the aspect ratio."
Hailuo-02-Standard,,,Text/Image-to-Video,10,768p,--duration,"MiniMax Hailuo-02 Video Generation model: Advanced image-to-video generation model with 768p resolution. Send a prompt with an image for image-to-video, and just a prompt for text-to-video generation. Use `--duration` to set the video duration (6 or 10 seconds). MiniMax Hailuo-02 Video Generation model: Advanced image-to-video generation model with 768p resolution. Send a prompt with an image for image-to-video, and just a prompt for text-to-video generation. Use `--duration` to set the video duration (6 or 10 seconds)."
Hailuo-02-Pro,,,Text/Image-to-Video,,1080p,,"MiniMax Hailuo-02 Pro Video Generation model: Advanced image-to-video generation model with 1080p resolution. Send a prompt with an image for image-to-video, and just a prompt for text-to-video generation. MiniMax Hailuo-02 Pro Video Generation model: Advanced image-to-video generation model with 1080p resolution. Send a prompt with an image for image-to-video, and just a prompt for text-to-video generation."
OmniHuman,,,Image+Audio-to-Video,30,,,"OmniHuman, by Bytedance, generates video using an image of a human figure paired with an audio file. It produces vivid, high-quality videos where the character’s emotions and movements maintain a strong correlation with the audio. Send an image including a human figure with a visible face, and an audio, and the bot will return a video. The maximum audio length accepted is 30 seconds. OmniHuman, by Bytedance, generates video using an image of a human figure paired with an audio file. It produces vivid, high-quality videos where the character’s emotions and movements maintain a strong correlation with the audio. Send an image including a human figure with a visible face, and an audio, and the bot will return a video. The maximum audio length accepted is 30 seconds."